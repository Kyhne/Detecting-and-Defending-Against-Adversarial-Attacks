# Detecting and Defending Against Adversarial Attacks
7th semester project. This is an extension of previous research extending defence against adversarial attacks via diffusion models to sentences as well as a novel approach in regards to detecting adversarial attacks. The first draft of our article is available in this repository.   

For the black-box attack and keyword spotter used in this project see https://github.com/nesl/adversarial_audio  

For the white-box attack used in this project see https://github.com/carlini/audio_adversarial_examples  

When running the code use DeepSpeech 0.9.3, Tensorflow-gpu 1.15.4, PyTorch 1.13.1+cu116, CUDA 10.1 and cuDNN 7.6.5.  

For the pre-trained diffusion model DiffWave the officially provided checkpoints is used and linked here: https://github.com/philsyn/DiffWave-unconditional/tree/master/exp/ch256_T200_betaT0.02/logs/checkpoint?fbclid=IwAR3MX0AMM7h8e-FIyF1EXJhVPI64AJAej61FVL_CicVCNABxJKx1MxRKUN8
